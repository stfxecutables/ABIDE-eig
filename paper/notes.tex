\documentclass[10pt]{article}
\usepackage{arxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage[english]{babel} % hyphenation
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsmath}        % https://tex.stackexchange.com/questions/41035/what-is-causing-undefined-control-sequence
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{bm}             % proper bolding
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
% \usepackage{lipsum}		% Can be removed after putting your text content
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{doi}

\include{meta}

\begin{document}
\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
  Resting-state functional magnetic resonance imaging (rs-fMRI) data has considerable potential for
  predicting neuropsychological and neurophysiological disorders, especially with modern machine
  learning (ML) and deep learning (DL) techniques. However, the low signal-to-noise ratio, and high
  dimensionality of this data make preparing rs-fMRI data for use in (ML) and/or (DL) challenging.
  We develop a preprocessing step for converting rs-fMRI images into spatially-rich 4D summary
  images by examining the eigenvalues of perturbations to the functional connectivity (FC). We use
  both classical ML algorithms and novel DL architectures developed to exploit this 4D information,
  and show that these "eigenperturbation" images have equal or greater predictive potential to the
  raw fMRI or other common FC-based approaches. We demonstrate the potential of these
  eigenperturbation images using the difficult ABIDE dataset, and obtain start of the art overall
  accuracies of [70\%-80\%].
\end{abstract}
\keywords{fMRI \and ABIDE \and deep learing \and convolutional neural network \and random matrix theory \and eigenvalues \and perturbation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}

Despite tremendous successes in computer vision and natural language processing, machine learning
(ML) and deep learning (DL) algorithms capable of handling higher-dimensional natural data are much
less well-established. The handling of 3D medical images is particularly challenging, due to
necessary pre-processing, unique normalization challenges, larger compute costs, and limited
sample sizes \citep[see][for a general review]{singh3DDeepLearning2020}.

Functional magnetic resonance images (fMRI) is especially challenging. The 4D nature of the data
means that a single preprocessed fMRI image can be hundreds of megabytes. A single fMRI is
essentially a (3D) video file\footnote{Except that while in a video file pixel values are in \([0,
255]\), in fMRI the voxel values can be any floating point value.}, and while there are well-known
and well-tested networks that are freely-available pre-trained for processing 2D \emph{images} (e.g.
ResNet, ResNext, MobileNet), efficient and effective models for processing even 2D video data are
still just beginning to be developed
\citep{xieRethinkingSpatiotemporalFeature2018,tranCloserLookSpatiotemporal2018,wangVideoModelingCorrelation2020}.
Attempts to process fMRI data in full are even less developed [cite examples].

In addition, there is only very limited publicly availabile fMRI data. While databases such as
OpenNeuro \citep{markiewiczOpenNeuroOpenResource2021} exist and cover a wide variety of domains, the
number of subjects and is typically far too small for machine learning applications, and the studies
are of very  low quality, and far too heterogenous to be usefully combined.

Perhaps the most popular publicly available fMRI dataset is the ABIDE I dataset, which includes 1112
resting-state fMRI (rs-fMRI) scans from 539 subjects with autism spectrum disorders (ASD) and 573
age-matched controls with typical development (TD) \citep{dimartinoAutismBrainImaging2014}. However,
while the ABIDE I dataset is an appropriate size for ML and DL approaches, it is particularly
challenging to work with due to the inclusion of subjects from 20 different sites. This results in
highly varied demographic and psychological characteristics and scanning parameters.

This heterogeneity makes ML and DL approaches difficult (see section \ref{existing-attempts} below
for a review). However, being able to handle such heterogenous and varied data is essential for
automated prediction procedures that are to be useful in clinical settings, or for any research that
seeks to acquire truly generalizable insights from fMRI data.

\subsection{Existing Approaches and Benchmarks} \label{existing-attempts}

TODO: Summarize results from notes in sections \ref{key-articles} and \ref{other-articles} here,
both verbally listing various approaches.

\subsubsection{ABIDE Validation Issues}

For heterogeneous data such as ABIDE, with 20 different data sources, validation itself poses a
unique challenge. As is clear from Table \ref{tab:existing-attempts}, smaller validation set sizes
(e.g. LOOCV, 10-fold) result in dramatically higher reported accuracies, as do small sample sizes.
We believe this is an obvious and direct consequence of the site-level heterogeneity present in the
ABIDE data.

\begin{itemize}
  \item
\end{itemize}

\begin{table}
	\caption{Overall accuracies of existing approaches. \(N\) = total number of subjects, \(N_{\text{ASD}}\) =
    total number of ASD subjects, \(N_{\text{TD}}\) = total number of TD subjects. LOOSO =
    Leave-one-site-out cross-validation. LOOCV = leave-one-out cross-validation.}
	\centering
	\begin{tabular}{lllllll}
		\toprule
		Study                                                         & Pipeline     & \(N\) & \(N_\text{ASD}\) & \(N_{\text{TD}}\) & Validation & Overall Accuracy \\
		\midrule
    \citet{heinsfeldIdentificationAutismSpectrum2018}             &              &       &                  &                   &            &                  \\
    \citet{eslamiASDDiagNetHybridLearning2019}                    &              &       &                  &                   &            &                  \\
    \citet{yinDiagnosisAutismSpectrum2021}                        &              &       &                  &                   &            &                  \\
		\citet{liMultisiteFMRIAnalysis2020}                           &              &       &                  &                   &            &                  \\
		\citet{el-gazzarHybrid3DCNN3DCLSTM2019}                       &              &       &                  &                   &            &                  \\
    \citet{shaoClassificationASDBased2021}                        &              &       &                  &                   &            &                  \\
    \citet{dekhilUsingRestingState2018}                           &              &       &                  &                   &            &                  \\
    \citet{parisotDiseasePredictionUsing2018}                     &              &       &                  &                   &            &                  \\
    \citet{sakaiMachineLearningStudies2019}                       &              &       &                  &                   &            &                  \\
    \citet{iidakaRestingStateFunctional2015}                      &              &       &                  &                   &            &                  \\
    \citet{liNovelTransferLearning2018}                           &              &       &                  &                   &            &                  \\
    \citet{kazeminejadTopologicalPropertiesRestingState2019}      &              &       &                  &                   &            &                  \\
    \citet{khoslaEnsembleLearning3D2019}                          &              &       &                  &                   &            &                  \\
    \citet{wangIdentifyingAutismSpectrum2020}                     &              &       &                  &                   &            &                  \\
    \citet{sherkatghanadAutomatedDetectionAutism2020}             &              &       &                  &                   &            &                  \\
    \citet{wangFunctionalConnectivitybasedClassification2019}     &              &       &                  &                   &            &                  \\
    \citet{yangDeepNeuralNetwork2020}                             &              &       &                  &                   &            &                  \\
    \citet{wangMAGEAutomaticDiagnosis2021}                        &              &       &                  &                   &            &                  \\
    \citet{ingalhalikarFunctionalConnectivitybasedPrediction2021} &              &       &                  &                   &            &                  \\
    \citet{yangLargeScaleBrainFunctional2021}                     &              &       &                  &                   &            &                  \\
    \citet{almuqhimASDSAENetSparseAutoencoder2021}                &              &       &                  &                   &            &                  \\
    \citet{byeonArtificialNeuralNetwork2020}                      &              &       &                  &                   &            &                  \\
		\bottomrule
	\end{tabular}
	\label{tab:existing-attempts}
\end{table}



\subsection{Prediction from 4D Spatial or Spatiotemporal Data}

In deep learning, it is common to divide the dimensions of the data into spatial and channel
dimensions. For example, colour images are usually described as multi-channel 2D, as there are
typically three colour dimensions (RGB), and two spatial dimensions (height and width). Channel
dimensions are special in that their \emph{ordering} is largely arbitrary: shuffling the order of
the channels has no meaningful impact on the semantics or usable information in the inputs.
Intuitively, channels represent parallel features with the same spatial dimensions.

Thus color video is multi-channel 3D: there are three color channels, and 3 spatial dimensions
(height, width, and time). The most natural approach to processing video is thus to take successful
multi-channel 2D networks (e.g. ResNet) and expand the convolutions to be 3D. However, the
computational costs of 3D convolution are considerably larger (a factor of [cite]
\citet{tranCloserLookSpatiotemporal2018}), and so much more successful papers have instead used
"channel-separated" or (2 + 1)D convolutions (\citet{tranCloserLookSpatiotemporal2018}), or other
methods like ..., or even methods which rethink how temporal information can be encoded via
correlations \cite{wangVideoModelingCorrelation2020}.

fMRI is truly 4D (one-channel) spatio-temporal data. To properly process this would require 4D
convolution, which is not implemented in most popular frameworks, and is extremely compute
intensive. Simple three-channel, 2D video (i.e. three-channel 3D) already runs into compute
problems, the 3D video data that comprise an fMRI image is especially difficult to handle
effectively.

In particular, the increased GPU memory and compute demands means that hyperparameter tuning, an
absolutely necessary step when investigating new network architectures, can be extremely expensive


Likewise, performance on messy data or data that has been corrupted even slightly results in often
dramatically degraded performance
\citep{metzUsingLearnedOptimizers2019,dodgeStudyComparisonHuman2017,hendrycksBenchmarkingNeuralNetwork2019,azulayWhyDeepConvolutional2019,rosenfeldElephantRoom2018}.
Whether or nor fMRI images contain a large amount of "noise" relative to "signal" depends on one's
analytic goals, however a number of factors (eye movement, heart rate, head movements, respiration
...) are detectable in fMRI signals [cite], and /emph{a priori} not of clear causal relevance to a
number of predictive goals.


\subsection{Feature Extraction via Correlation Eigenvalues}

An fMRI image \(\bm{F}\) is a tensor or array with shape \texttt{(H,W,D,T)}, where \texttt{H},
\texttt{W}, \texttt{D}, and \texttt{T} are the sizes of the height, width, depth, and time
dimensions, respectively. The flattened array \(F\) thus has shape \((N = \texttt{H} \times
\texttt{W} \times \texttt{D}, \texttt{T})\), such that \texttt{N} is the total number of voxels in
the image (air voxels included). A region of interest (ROI) we denote with \(R\), and each of the
\(n\) ROIs \(R_i\) of \(\bm{F}\) has shape \((N_i, \texttt{T})\), where \(\sum_i^n N_i= N\). ROIs
are defined by an \emph{atlas}, which is an array of integers of shape \texttt{(H,W,D)}, with
integer values up to \(n\).

DUe to the multi-site nature of the ABIDE data, the number of timepoints and repetition time (TR)
vary across scans. ([TODO]: see Table or Histogram). However, deep or machine learning algorithms
require inputs to be of the same size (if not generally, then in mini-batches of more than one
input). While cropping, padding or interpolation are usually used to overcome such issues, these
techniques are more difficult to justify when the underlying sampling rates differ and signals are
noisy, and are likely to lead to poor generalization and memorization when sampling rates and image
sizes vary significantly. I.e. padded inputs occupy completely different regions of space and so
will form a clearly separable cluster, cropped inputs with different sampling rates represent
different amounts of measurement time, and interpolated inputs are likely to have increased
correlations between features (voxels) unless the interpolation is downsampling and does not apply
any averaging or smoothing (e.g. as in nearest-neighbour interpolation).

Thus there is a challenge of converting all images to some common representation which is relatively
insensitive to these temporal differences, or which eliminates these differences while retaining
rich information about the original signals.

One recent finding has been that the functional connectivity of rs-fMRI is surprisingly robust to the
the underlying sampling rate \citep{huotariSamplingRateEffects2019,shakilEvaluationSlidingWindow2016}

\subsection{Previous Approaches}

TODO: Summarize various studies listed in notes below (\ref{key-articles} and \ref{other-articles})
in table or other condensed form.

% \citet{eslamiASDDiagNetHybridLearning2019} use an autoencoder to


\section{Methods}

\subsection{ABIDE Data}

Publicly availabile fMRI data is limited. While databases such as OpenNeuro
\citep{markiewiczOpenNeuroOpenResource2021} exist and cover a wide variety of domains, the number
of subjects is typically far too small for machine learning applications, and the studies are far
too heterogenous to be usefully combined. Perhaps the most popular publicly available fMRI dataset
is the ABIDE I dataset, which includes 1112 resting-state fMRI (rs-fMRI) scans from 539 subjects
with autism spectrum disorders (ASD) and 573 age-matched controls with typical development (TD)
\citep{dimartinoAutismBrainImaging2014}.

The ABIDE I dataset is an appropriate size for ML and DL approaches, but is particularly challenging
due to the inclusion of subjects from 20 different sites. This results in highly varied demographic
and psychological characteristics and scanning parameters. While this heterogeneity makes ML and DL
approaches difficult, it also means that if such an approach performs well on this data, that it has
much more potential clinical utility and relevance.


The ABIDE I dataset \citep{dimartinoAutismBrainImaging2014} is a publicly acessible rs-fMRI dataset of over
1112 subjects, 539 of which are diagnosed with Autism Spectrum Disorder (ASD),
and 573 of which are typical development (TD). The data are collected from 17 different sites with
varying scan parameters, and subjects vary considerably in age, making the dataset analytically
challenging. However, the high heterogeneity of the data also makes it more suitable for testing the
generalizability of modern predictive methods, and methods that perform well on the ABIDE data
\emph{a priori} have more potential clinical utility.

The ABIDE I data is available fully-preprocessed, and investigators can choose from a number of
pre-processing pipelines and options. The main options involve filtering (bandpass filtering, global
signal regression), and a choice of one of four pipelines \citep{dimartinoAutismBrainImaging2014}.
However, to keep analyses consistent with similar papers
\citet{abrahamDerivingReproducibleBiomarkers2017, mostafaDiagnosisAutismSpectrum2019,
yinDiagnosisAutismSpectrum2021, heinsfeldIdentificationAutismSpectrum2018} we use the subjects from
the Configurable Pipeline for the Analysis of Connectomes
\citep[CPAC;][]{cameronAutomatedAnalysisConnectomes2013}, and exclude subjects that fail to pass quality
control checks from three independent experts \citep[see][for
details]{abrahamDerivingReproducibleBiomarkers2017}, giving a final total of 871 subjects (XXX ASD,
XXX TD).



\subsubsection{ROI Means}

These are available from the CPAC pipeline for direct download [cite]. In the interest of reproducibility we simply
use these directly.

\subsubsection{ROI Standard Deviations}






\newpage

\section{Key Articles} \label{key-articles}

Note for below I also seem to use the CPAC minimal pipeline, I think.

Of studies that get above e.g. 70.3\% accuracy, there is \emph{almost always} some cheaty feature
selection using all subjects, completely negating the final 10-fold or whatever accuracy values. No
\emph{honest} techniques make it above 70\% accuracy across sites yet \emph{except}
\citet{mostafaDiagnosisAutismSpectrum2019,yinDiagnosisAutismSpectrum2021}, who use eigenvalues of
the graph of the Laplacian of the thresholded correlation matrix.

\subsection{Use of Eigenvalues for Prediction! \citet{mostafaDiagnosisAutismSpectrum2019}} \label{eig-pred}



\subsection{\citet{heinsfeldIdentificationAutismSpectrum2018}}

\begin{itemize}
  \item 70\% with C-PAC preprocessing pipeline
  \item used CC200 atlas to reduce to ROI feature vectors (i.e. not CNN)
  \item actually used functional connectivity as the predictor
  \item used 10-fold validation across all sites (good!)
  \item used a deep denoising autoencoder (really just MLP with some augmentation / dropout on inputs)
\end{itemize}
\subsection{\citet{eslamiASDDiagNetHybridLearning2019}}

Decent. Very similar to ours in spirit.

\begin{itemize}
  \item 1112 subjects from almost all sites
  \item CPAC pipeline with CC200 functional ROIs
  \item use only some correlations (e.g. select smallest and largest correlations (most negative?))
  \item train single-layer autoencoder first to do e.g. a non-linear PCA first for reduction /
  embedding
  \item use SMOTE to \textbf{augment their data!} (basically, linearly interpolate a new sample from
  5 nearest samples), effectively doubles the training set size
  \item get to 70.3\% accuracy (their augmentation adds only 1\%)
\end{itemize}

\subsection{\citet{yinDiagnosisAutismSpectrum2021}}

\textbf{VERY GOOD}, same authors as \citet{mostafaDiagnosisAutismSpectrum2019}.

\begin{itemize}
  \item 871 subjects, custom preprocessing (minimal), 264 ROI parcellation, Pearson corrs
  \item also threshold map to largest (in abs. value) correlations (e.g. all correlations greater in
  absolute value then a threshold go to 1 or -1, so matrix becomes an adjacency matrix)
  \item then compute a Laplacian matrix (very simple, see article) from adjacency matrix
  \item then get eigenvalues from this
  \item compute a bunch of other graph-theoretic metrics from this Laplacian matrix
  \item interestingly \textbf{min-max normalize} their eigenvalues within subjects
  \item do not contaminate their autoencoder (proper splitting of training and testing)
  \begin{itemize}
    \item however the splitting is a little bit fucky since it means pre-training
  \end{itemize}
  \item without autoencoder pre-training and just using their graph features, get DNN acc of 76.2\%
  \begin{itemize}
    \item interestingly find that need a lower threshold (allow all correlations above 0.2) for this
    deep learner, which might be relevant for me since right now I am taking only top 25
    eigenvalues, which is probably not enough (see Table 2 of their study, very interesting!)
  \end{itemize}
\end{itemize}

\section{Other Articles} \label{other-articles}


\subsection{\citet{liMultisiteFMRIAnalysis2020}}

\begin{itemize}
  \item 70\% with C-PAC preprocessing pipeline
  \item similar number of subjects to us
  \item used sliding windows (32 timepoints long) of mean ROI sequences (HO Atlas, 111 ROIs)
  \item interesting comparison points is \emph{sex classification accuracy} which was only between
  \item report no overall accuracy, but NYU hardest to classify (67.6\% at best), USM easiest (up to
  84.9\%)
  \item validation splits are unclear
\end{itemize}

\subsection{\citet{el-gazzarHybrid3DCNN3DCLSTM2019}}

\begin{itemize}
  \item used Conv3D to Conv1D or ConvLSTM (they test both)
  \item CPAC pipeline for ABIDE
  \item only use single-site validation (losers) also NYU and UM (easiest)
  \item also do one multi-site with 19 sites 1100 subjects
  \item patch-based training where prediction is average prediction over crops
  \item max 5-fold acc of \(0.77 \pm 0.05\) on NYU with Conv3dConvLSTM3d
\end{itemize}

\begin{table}
\caption{\citet{el-gazzarHybrid3DCNN3DCLSTM2019} 5-fold cross-site results}
\centering
  \begin{tabular}{lll}
    \toprule
    % \multicolumn{2}{c}{Part}                   \\
    % \cmidrule(r){1-2}
    Model     & Accuracy     & F1-score \\
    \midrule
    AE MLP        [8]   &  0.63 \(\pm\) 0.02  & 0.64 \\
    SVM           [5]   &  0.58 \(\pm\) 0.04  & 0.60 \\
    1D Conv       [7]   &  0.64 \(\pm\) 0.06  & 0.64 \\
    3DCNN 1D     (ours) &  0.54 \(\pm\) 0.02  & 0.50 \\
    3DCNN C-LSTM (ours) &  0.58 \(\pm\) 0.03  & 0.53 \\

    \bottomrule
  \end{tabular}
  \label{tab:table}
\end{table}

\subsection{\citet{shaoClassificationASDBased2021}}

\begin{itemize}
  \item GCN (graph convolutional network) plus another network that learns feature weights
  \item use CPAC preprocessed data, but \textbf{discard 241 ghosty / bad-looking data} to get a
  total of 871 subjects
  \item used mean series on some of HO (Harvard-Oxford) atlas, standardized to zero mean and unit variance
  \item 111 ROIs total
  \item do feature selection and also test various models
  \item GCN gets \(79.5\pm3.3\)\% acc (3.3 is sd), 10-fold validation
\end{itemize}

\subsection{\citet{dekhilUsingRestingState2018}}
\begin{itemize}
  \item  fMRI data for 123 ASD and 160 TD children and adolescents (for a total number of 283
  subjects) from the National Database for Autism Research (NDAR: http://ndar.nih.gov)
  \item all Ps have both MRI and rs-fMRI scans
  \item do register, BET, slicetime, motion, and then spatial Gaussian spatial smoothing
  \item extract 34 ROIs via ICA
  \item features for prediction are the \textbf{power spectral densities}
  \item get very high accuracy, but isn't ABIDE, and is one site
\end{itemize}

\subsection{\citet{parisotDiseasePredictionUsing2018}}
\begin{itemize}
  \item ``Our analysis shows that our novel framework can improve over state-of-the-art results on
  both databases, with 70.4\% classification accuracy for ABIDE''
  \item 871 subjects (remove a lot of bad scans) from CPAC pipeline
  \item GCN on correlation matrices between HO atlas mean ROI signals (plus some fancy normalization
  / filtering), with recursive feature selection
  \item stratified grouped 10-fold to get the 70.4\% acc
\end{itemize}

\subsection{\citet{sakaiMachineLearningStudies2019}}

See Table 9 of this one for ABIDE accuracies. There are some spuriously high and extremely unlikely
out-of-bag accuracies of 0.90 or on tiny sample. Otherwise, of note is
\citet{iidakaRestingStateFunctional2015} who apparently get an LOOCV of 0.90 (??? dubious).

\subsection{\citet{iidakaRestingStateFunctional2015}}

\begin{itemize}
  \item only subjects under 20
  \item 640 subjects total
  \item 2-fold acc was 77.2\%, 10-fold was 86.9\%
  \item did do some bandpass filtering as pre-processing, drop first 5 volumes
  \item features are 90 AAL mean normalized ROI regions correlation matrix (r-values fisher
  normalized to Z-scores)
\end{itemize}

\subsection{\citet{liNovelTransferLearning2018}}

\begin{itemize}
  \item pre-train stacked autoencoder on different data healthy rs-fMRI first
  \item ABIDE used Connectome Computation System preprocessed
  \item \textbf{regressed out height, age, sex, site} from among ROI correlations
  \item never get above 70.4\% acc, and only within USM, so not good
\end{itemize}

\subsection{\citet{kazeminejadTopologicalPropertiesRestingState2019}}

\begin{itemize}
  \item CPAC pipeline, 116 AAL regions
  \item features are multiple correlation matrices (e.g. Pearson, Spearman, partial correlation,
  mutual information) converted to graphs via thresholding
  \item Gaussian SVM classifier (sklearn), step-up feature selection
  \item validation is 10-fold, but very dubious procedure, sounds / unclear how feature selection is
  being done here, almost certainly overfitting a lot
  \item no overall reported accuracy, just report stratified by ages, sad, lame, (lol Frontiers)
\end{itemize}


\subsection{\citet{khoslaEnsembleLearning3D2019}}

\textbf{Note that choice of atlas doesn't matter}, we could use this as a citation for motivating
our non-atlas-based approach!

\begin{itemize}
  \item CPAC pipeline, but did some extra expert / manual scrubbing and quality control (manual and
  automatic), exclude very young and very old, which brought them down to  \textbf{163 ASD / 230
  CTRL}
  \item looked at all ROIs from all atlases
  \item get to about 72.8\% acc with CC200 parcellation and 3D-CNN (Table 2)
  \item various other models all get to around 71.2\%, 71.7\%, 72.3\%, etc
\end{itemize}

\subsection{\citet{wangIdentifyingAutismSpectrum2020}}

\begin{itemize}
  \item 468 subjects, CPAC pipeline, AAL 116 mean time series
  \item don't really report clean overall accuracies because they are doing domain adaptation
  (training on non-NYU data and predicting NYU data) but basically when having similar validation
  sizes as us (e.g. about 40\%) are also in the 69-73\% range of accuracy
\end{itemize}

\subsection{\citet{sherkatghanadAutomatedDetectionAutism2020}}

\textbf{Would be good to try to replicate these dubious results}

\begin{itemize}
  \item CPAC pipeline, 871 "quality" images, CC400 parcellation
  \item shallow (but wide) CNN used directly on correlation matrix
  \item 10-fold acc of 70.2\%
\end{itemize}

\subsection{\citet{wangFunctionalConnectivitybasedClassification2019}}

Very curious, given how shallow network is and how simple approach is...

\begin{itemize}
  \item reports a crazy cross-site accuracy of \textbf{over 90\%}
  \item  531 subjects(255AD / 276CTRL), DPARSF pipeline, also did some QC
  \item 75-95\% acc based on "leave-one-site-out"
  \item 90.6\% acc on all sites with SVM
  \item key thing is a recursive, SVM-based step-down feature selection procedure on ROIs
  \item \textbf{HOWEVER is overfit because all 531 subjects used in feature selection... lol}
\end{itemize}

\subsection{\citet{yangDeepNeuralNetwork2020}}

Probably \textbf{worth trying to replicate this} given the stupid simplicity

\begin{itemize}
  \item CC400 atlas, ROI correlation matrix, pathetically simply MLP, 1035 subjects
  \item claim to get 5-fold acc of 75.3\%
  \item cross-validated grid-search of classifiers, so perhaps just overfitting the extra 4\%?
\end{itemize}

\subsection{\citet{wangMAGEAutomaticDiagnosis2021}}

\begin{itemize}
  \item 949 subjects, CPAC pipeline
  \item 75.86\% accuracy, 10-fold
  \item multi-atlas Graph CNNs (ensemble learning), recursive feature elimination
  \item show single-atlas based models get 70-72\% acc
  \item \textbf{feature selection subjects completely unclear, another cheat}
\end{itemize}

\subsection{\citet{ingalhalikarFunctionalConnectivitybasedPrediction2021}}

\begin{itemize}
  \item most subjects, DPARSF pipeline, "cross-site harmomnization" with denoising autoencoder
  \item 71.35\% 10-fold ACC with ANN
\end{itemize}

\subsection{\citet{yangLargeScaleBrainFunctional2021}}

77.74\% 1-fold mean acc but with small number of subjects, only NYU (lame)

\subsection{\citet{almuqhimASDSAENetSparseAutoencoder2021}}

\begin{itemize}
  \item claims \citet{eslamiASDDiagNetHybridLearning2019} is current state of art (70.3\%)
  \item CPAC pipeline, CC200, correlation matrix, only one triangle, 1/4 largest, 1/4 smallest
  \item sparse autoencoder to force embedding
  \item get 10-fold overall acc of 70.8\%
\end{itemize}

\subsection{\citet{byeonArtificialNeuralNetwork2020}}

\begin{itemize}
  \item CPAC, only subjects with TR=2.0 (270 ASD, 305 TD) and good QC
  \item BrainNetome atlas mean signals (246 ROI)
  \item use first 146 timepoints only to make subjects all same size
  \item 74.5\% accuracy, 5-fold
\end{itemize}

\section{Headings: first level}
\label{sec:headings}

See Section \ref{sec:headings}.

\subsection{Headings: second level}
\paragraph{Paragraph}

A footnote \footnote{Sample of the first footnote.}.

\bibliographystyle{unsrtnat}
\bibliography{references}

\end{document}