\documentclass[10pt]{article}
\usepackage{arxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage[english]{babel} % hyphenation
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
% \usepackage{lipsum}		% Can be removed after putting your text content
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{doi}

\include{meta.tex}

\begin{document}
\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
  Functional magnetic resonance imaging (fMRI) data has considerable potential for predicting
  neuropsychological and neurophysiological disorders. However, processing this data for use in
  machine learning (ML) and/or deep learning (DL) algorithms is challenging. We implement both novel
  deep learning architectures and a preprocessing step for converting fMRI images into
  spatially-rich 4D summary images with the same or greater predictive potential as the raw fMRI. We
  show that tuned models on these summary "eigen-perturbation" images are just as accurate as on the
  fMRI original images, despite a \(10-20\) times reduction in size, and achieve state-of-the-art
  accuracy of [over 70\% so far] on a \emph{large}, cross-site validation set.
\end{abstract}
\keywords{fMRI \and ABIDE \and deep learing \and convolutional neural network \and random matrix theory \and eigenvalues \and perturbation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

Despite tremendous successive in multi-channel 2D and natural language processing, algorithms
capable of handling higher-dimensional tensors are less established. For example, while there are
well-known and well-tested networks that are freely-available pre-trained for processing 2D images
(e.g. ResNet, ResNext, MobileNet), models for processing video data are less well known. For
example, PyTorch makes available only the models from \citet{tranCloserLookSpatiotemporal2018}. The
principles underlying good design of 3D CNNs are still just being investigated
\citep{xieRethinkingSpatiotemporalFeature2018}.

In deep learning, it is common to divide the dimensions of the data into spatial and channel
dimensions. For example, colour images are usually described as multi-channel 2D, as there are
typically three colour dimensions (RGB), and two spatial dimensions (height and width). Channel
dimensions are special in that their \emph{ordering} is largely arbitrary: shuffling the order of
the channels has no meaningful impact on the semantics or usable information in the inputs.
Intuitively, channels represent parallel features with the same spatial dimensions.

Thus color video is multi-channel 3D: there are three color channels, and 3 spatial dimensions
(height, width, and time). The most natural approach to processing video is thus to take successful
multi-channel 2D networks (e.g. ResNet) and expand the convolutions to be 3D. However, the
computational costs of 3D convolution are considerably larger (a factor of [cite]
\citet{tranCloserLookSpatiotemporal2018}), and so much more successful papers have instead used
"channel-separated" or (2 + 1)D convolutions (\citet{tranCloserLookSpatiotemporal2018}), or other
methods like ..., or even methods which rethink how temporal information can be encoded via
correlations \cite{wangVideoModelingCorrelation2020}.

\subsection{fMRI and Prediction}

However, fMRI is truly one-channel 4D spatial data. To properly process
this would require 4D convolution, which is not implemented in most popular frameworks, and is
extremely compute intensive. As simple three-channel 2D video (i.e. three-channel 3D) already runs
into compute problems, the 3D video data that comprise an fMRI image is especially difficult to
handle effectively.

In particular, the increased GPU memory and compute demands means that hyperparameter tuning, an
absolutely necessary step when investigating new network architectures, can be extremely expensive


Likewise, performance on messy data or data that has been corrupted even slightly results in often
dramatically degraded performance
\citep{metzUsingLearnedOptimizers2019,dodgeStudyComparisonHuman2017,hendrycksBenchmarkingNeuralNetwork2019,azulayWhyDeepConvolutional2019,rosenfeldElephantRoom2018}.
Whether or nor fMRI images contain a large amount of "noise" relative to "signal" depends on one's
analytic goals, however a number of factors (eye movement, heart rate, head movements, respiration
...) are detectable in fMRI signals [cite], and /emph{a priori} not of clear causal relevance to a
number of predictive goals.

\subsection{Previous Approaches}


An additional challenge with fMRI is the number of confounding variables that ultimately result in a


\section{Methods}

\subsection{ABIDE Data}

The ABIDE I dataset \citep{dimartinoAutismBrainImaging2014} is a publicly acessible rs-fMRI dataset of over
1112 subjects, 539 of which are diagnosed with Autism Spectrum Disorder (ASD),
and 573 of which are typical development (TD). The data are collected from 17 different sites with
varying scan parameters, and subjects vary considerably in age, making the dataset analytically
challenging. However, the high heterogeneity of the data also makes it more suitable for testing the
generalizability of modern predictive methods, and methods that perform well on the ABIDE data
\emph{a priori} have more potential clinical utility.

The ABIDE I data is available fully-preprocessed, and investigators can choose from a number of
pre-processing pipelines and options. The main options involve filtering (bandpass filtering, global
signal regression), and a choice of one of four pipelines \citep{dimartinoAutismBrainImaging2014}.
However, to keep analyses consistent with similar papers
\citet{abrahamDerivingReproducibleBiomarkers2017, mostafaDiagnosisAutismSpectrum2019,
yinDiagnosisAutismSpectrum2021, heinsfeldIdentificationAutismSpectrum2018} we use the subjects from
the Configurable Pipeline for the Analysis of Connectomes
\citep{cameronAutomatedAnalysisConnectomes2013}, and exclude subjects that fail to pass quality
control checks from three independent experts \citep[see][for
details]{abrahamDerivingReproducibleBiomarkers2017}, giving a final total of 871 subjects (XXX ASD,
XXX TD).

\subsection{Feature Extraction}

\subsubsection{ROI Means}

These are available from the CPAC pipeline for direct download [cite]. In the interest of reproducibility we simply
use these directly.

\subsubsection{ROI Standard Deviations}






\newpage

\section{Key Articles}

Note for below I also seem to use the CPAC minimal pipeline, I think.

Of studies that get above e.g. 70.3\% accuracy, there is \emph{almost always} some cheaty feature
selection using all subjects, completely negating the final 10-fold or whatever accuracy values. No
\emph{honest} techniques make it above 70\% accuracy across sites yet \emph{except}
\citet{mostafaDiagnosisAutismSpectrum2019,yinDiagnosisAutismSpectrum2021}, who use eigenvalues of
the graph of the Laplacian of the thresholded correlation matrix.

\subsection{Use of Eigenvalues for Prediction! \citet{mostafaDiagnosisAutismSpectrum2019}}



\subsection{\citet{heinsfeldIdentificationAutismSpectrum2018}}

\begin{itemize}
  \item 70\% with C-PAC preprocessing pipeline
  \item used CC200 atlas to reduce to ROI feature vectors (i.e. not CNN)
  \item actually used functional connectivity as the predictor
  \item used 10-fold validation across all sites (good!)
  \item used a deep denoising autoencoder (really just MLP with some augmentation / dropout on inputs)
\end{itemize}
\subsection{\citet{eslamiASDDiagNetHybridLearning2019}}

Decent. Very similar to ours in spirit.

\begin{itemize}
  \item 1112 subjects from almost all sites
  \item CPAC pipeline with CC200 functional ROIs
  \item use only some correlations (e.g. select smallest and largest correlations (most negative?))
  \item train single-layer autoencoder first to do e.g. a non-linear PCA first for reduction /
  embedding
  \item use SMOTE to \textbf{augment their data!} (basically, linearly interpolate a new sample from
  5 nearest samples), effectively doubles the training set size
  \item get to 70.3\% accuracy (their augmentation adds only 1\%)
\end{itemize}

\subsection{\citet{yinDiagnosisAutismSpectrum2021}}

\textbf{VERY GOOD}, same authors as \citet{mostafaDiagnosisAutismSpectrum2019}.

\begin{itemize}
  \item 871 subjects, custom preprocessing (minimal), 264 ROI parcellation, Pearson corrs
  \item also threshold map to largest (in abs. value) correlations (e.g. all correlations greater in
  absolute value then a threshold go to 1 or -1, so matrix becomes an adjacency matrix)
  \item then compute a Laplacian matrix (very simple, see article) from adjacency matrix
  \item then get eigenvalues from this
  \item compute a bunch of other graph-theoretic metrics from this Laplacian matrix
  \item interestingly \textbf{min-max normalize} their eigenvalues within subjects
  \item do not contaminate their autoencoder (proper splitting of training and testing)
  \begin{itemize}
    \item however the splitting is a little bit fucky since it means pre-training
  \end{itemize}
  \item without autoencoder pre-training and just using their graph features, get DNN acc of 76.2\%
  \begin{itemize}
    \item interestingly find that need a lower threshold (allow all correlations above 0.2) for this
    deep learner, which might be relevant for me since right now I am taking only top 25
    eigenvalues, which is probably not enough (see Table 2 of their study, very interesting!)
  \end{itemize}
\end{itemize}

\section{Other Articles}


\subsection{\citet{liMultisiteFMRIAnalysis2020}}

\begin{itemize}
  \item 70\% with C-PAC preprocessing pipeline
  \item similar number of subjects to us
  \item used sliding windows (32 timepoints long) of mean ROI sequences (HO Atlas, 111 ROIs)
  \item interesting comparison points is \emph{sex classification accuracy} which was only between
  \item report no overall accuracy, but NYU hardest to classify (67.6\% at best), USM easiest (up to
  84.9\%)
  \item validation splits are unclear
\end{itemize}

\subsection{\citet{el-gazzarHybrid3DCNN3DCLSTM2019}}

\begin{itemize}
  \item used Conv3D to Conv1D or ConvLSTM (they test both)
  \item CPAC pipeline for ABIDE
  \item only use single-site validation (losers) also NYU and UM (easiest)
  \item also do one multi-site with 19 sites 1100 subjects
  \item patch-based training where prediction is average prediction over crops
  \item max 5-fold acc of \(0.77 \pm 0.05\) on NYU with Conv3dConvLSTM3d
\end{itemize}

\begin{table}
\caption{\citet{el-gazzarHybrid3DCNN3DCLSTM2019} 5-fold cross-site results}
\centering
  \begin{tabular}{lll}
    \toprule
    % \multicolumn{2}{c}{Part}                   \\
    % \cmidrule(r){1-2}
    Model     & Accuracy     & F1-score \\
    \midrule
    AE MLP        [8]   &  0.63 \(\pm\) 0.02  & 0.64 \\
    SVM           [5]   &  0.58 \(\pm\) 0.04  & 0.60 \\
    1D Conv       [7]   &  0.64 \(\pm\) 0.06  & 0.64 \\
    3DCNN 1D     (ours) &  0.54 \(\pm\) 0.02  & 0.50 \\
    3DCNN C-LSTM (ours) &  0.58 \(\pm\) 0.03  & 0.53 \\

    \bottomrule
  \end{tabular}
  \label{tab:table}
\end{table}

\subsection{\citet{shaoClassificationASDBased2021}}

\begin{itemize}
  \item GCN (graph convolutional network) plus another network that learns feature weights
  \item use CPAC preprocessed data, but \textbf{discard 241 ghosty / bad-looking data} to get a
  total of 871 subjects
  \item used mean series on some of HO (Harvard-Oxford) atlas, standardized to zero mean and unit variance
  \item 111 ROIs total
  \item do feature selection and also test various models
  \item GCN gets \(79.5\pm3.3\)\% acc (3.3 is sd), 10-fold validation
\end{itemize}

\subsection{\citet{dekhilUsingRestingState2018}}
\begin{itemize}
  \item  fMRI data for 123 ASD and 160 TD children and adolescents (for a total number of 283
  subjects) from the National Database for Autism Research (NDAR: http://ndar.nih.gov)
  \item all Ps have both MRI and rs-fMRI scans
  \item do register, BET, slicetime, motion, and then spatial Gaussian spatial smoothing
  \item extract 34 ROIs via ICA
  \item features for prediction are the \textbf{power spectral densities}
  \item get very high accuracy, but isn't ABIDE, and is one site
\end{itemize}

\subsection{\citet{parisotDiseasePredictionUsing2018}}
\begin{itemize}
  \item ``Our analysis shows that our novel framework can improve over state-of-the-art results on
  both databases, with 70.4\% classification accuracy for ABIDE''
  \item 871 subjects (remove a lot of bad scans) from CPAC pipeline
  \item GCN on correlation matrices between HO atlas mean ROI signals (plus some fancy normalization
  / filtering), with recursive feature selection
  \item stratified grouped 10-fold to get the 70.4\% acc
\end{itemize}

\subsection{\citet{sakaiMachineLearningStudies2019}}

See Table 9 of this one for ABIDE accuracies. There are some spuriously high and extremely unlikely
out-of-bag accuracies of 0.90 or on tiny sample. Otherwise, of note is
\citet{iidakaRestingStateFunctional2015} who apparently get an LOOCV of 0.90 (??? dubious).

\subsection{\citet{iidakaRestingStateFunctional2015}}

\begin{itemize}
  \item only subjects under 20
  \item 640 subjects total
  \item 2-fold acc was 77.2\%, 10-fold was 86.9\%
  \item did do some bandpass filtering as pre-processing, drop first 5 volumes
  \item features are 90 AAL mean normalized ROI regions correlation matrix (r-values fisher
  normalized to Z-scores)
\end{itemize}

\subsection{\citet{liNovelTransferLearning2018}}

\begin{itemize}
  \item pre-train stacked autoencoder on different data healthy rs-fMRI first
  \item ABIDE used Connectome Computation System preprocessed
  \item \textbf{regressed out height, age, sex, site} from among ROI correlations
  \item never get above 70.4\% acc, and only within USM, so not good
\end{itemize}

\subsection{\citet{kazeminejadTopologicalPropertiesRestingState2019}}

\begin{itemize}
  \item CPAC pipeline, 116 AAL regions
  \item features are multiple correlation matrices (e.g. Pearson, Spearman, partial correlation,
  mutual information) converted to graphs via thresholding
  \item Gaussian SVM classifier (sklearn), step-up feature selection
  \item validation is 10-fold, but very dubious procedure, sounds / unclear how feature selection is
  being done here, almost certainly overfitting a lot
  \item no overall reported accuracy, just report stratified by ages, sad, lame, (lol Frontiers)
\end{itemize}


\subsection{\citet{khoslaEnsembleLearning3D2019}}

\textbf{Note that choice of atlas doesn't matter}, we could use this as a citation for motivating
our non-atlas-based approach!

\begin{itemize}
  \item CPAC pipeline, but did some extra expert / manual scrubbing and quality control (manual and
  automatic), exclude very young and very old, which brought them down to  \textbf{163 ASD / 230
  CTRL}
  \item looked at all ROIs from all atlases
  \item get to about 72.8\% acc with CC200 parcellation and 3D-CNN (Table 2)
  \item various other models all get to around 71.2\%, 71.7\%, 72.3\%, etc
\end{itemize}

\subsection{\citet{wangIdentifyingAutismSpectrum2020}}

\begin{itemize}
  \item 468 subjects, CPAC pipeline, AAL 116 mean time series
  \item don't really report clean overall accuracies because they are doing domain adaptation
  (training on non-NYU data and predicting NYU data) but basically when having similar validation
  sizes as us (e.g. about 40\%) are also in the 69-73\% range of accuracy
\end{itemize}

\subsection{\citet{sherkatghanadAutomatedDetectionAutism2020}}

\textbf{Would be good to try to replicate these dubious results}

\begin{itemize}
  \item CPAC pipeline, 871 "quality" images, CC400 parcellation
  \item shallow (but wide) CNN used directly on correlation matrix
  \item 10-fold acc of 70.2\%
\end{itemize}

\subsection{\citet{wangFunctionalConnectivitybasedClassification2019}}

Very curious, given how shallow network is and how simple approach is...

\begin{itemize}
  \item reports a crazy cross-site accuracy of \textbf{over 90\%}
  \item  531 subjects(255AD / 276CTRL), DPARSF pipeline, also did some QC
  \item 75-95\% acc based on "leave-one-site-out"
  \item 90.6\% acc on all sites with SVM
  \item key thing is a recursive, SVM-based step-down feature selection procedure on ROIs
  \item \textbf{HOWEVER is overfit because all 531 subjects used in feature selection... lol}
\end{itemize}

\subsection{\citet{yangDeepNeuralNetwork2020}}

Probably \textbf{worth trying to replicate this} given the stupid simplicity

\begin{itemize}
  \item CC400 atlas, ROI correlation matrix, pathetically simply MLP, 1035 subjects
  \item claim to get 5-fold acc of 75.3\%
  \item cross-validated grid-search of classifiers, so perhaps just overfitting the extra 4\%?
\end{itemize}

\subsection{\citet{wangMAGEAutomaticDiagnosis2021}}

\begin{itemize}
  \item 949 subjects, CPAC pipeline
  \item 75.86\% accuracy, 10-fold
  \item multi-atlas Graph CNNs (ensemble learning), recursive feature elimination
  \item show single-atlas based models get 70-72\% acc
  \item \textbf{feature selection subjects completely unclear, another cheat}
\end{itemize}

\subsection{\citet{ingalhalikarFunctionalConnectivitybasedPrediction2021}}

\begin{itemize}
  \item most subjects, DPARSF pipeline, "cross-site harmomnization" with denoising autoencoder
  \item 71.35\% 10-fold ACC with ANN
\end{itemize}

\subsection{\citet{yangLargeScaleBrainFunctional2021}}

77.74\% 1-fold mean acc but with small number of subjects, only NYU (lame)

\subsection{\citet{almuqhimASDSAENetSparseAutoencoder2021}}

\begin{itemize}
  \item claims \citet{eslamiASDDiagNetHybridLearning2019} is current state of art (70.3\%)
  \item CPAC pipeline, CC200, correlation matrix, only one triangle, 1/4 largest, 1/4 smallest
  \item sparse autoencoder to force embedding
  \item get 10-fold overall acc of 70.8\%
\end{itemize}
k

\section{Headings: first level}
\label{sec:headings}

See Section \ref{sec:headings}.

\subsection{Headings: second level}
\paragraph{Paragraph}

A footnote \footnote{Sample of the first footnote.}.

\bibliographystyle{unsrtnat}
\bibliography{references}

\end{document}