\documentclass[10pt]{article}
\usepackage{arxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage[english]{babel} % hyphenation
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
% \usepackage{lipsum}		% Can be removed after putting your text content
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{doi}

\include{meta.tex}

\begin{document}
\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
  Functional magnetic resonance imaging (fMRI) data has considerable potential
  for predicting neuropsychological and neurophysiological disorders. However, processing this data
  for use in machine learning (ML) and/or deep learning (DL) algorithms is challenging. In this
  paper we implement both novel deep learning architectures and a preprocessing step for converting
  fMRI images into spatially-rich 4D summary images with the same or greater predictive potential as
  the raw fMRI. We show that tuned models on these summary "eigen-perturbation" images are just as
  accurate as on the fMRI original images, despite a \(10-20\) times reduction in size, and achieve
  state-of-the-art accuracy of [over 70\% we hope!] on a \emph{large}, cross-site validation set.
\end{abstract}
\keywords{fMRI \and ABIDE \and deep learing \and convolutional neural network \and random matrix theory \and eigenvalues \and perturbation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Key Articles}

\subsection{\citet{heinsfeldIdentificationAutismSpectrum2018}}

\begin{itemize}
  \item 70\% with C-PAC preprocessing pipeline
  \item used CC200 atlas to reduce to ROI feature vectors (i.e. not CNN)
  \item actually used functional connectivity as the predictor
  \item used 10-fold validation across all sites (good!)
  \item used a deep denoising autoencoder (really just MLP with some augmentation / dropout on inputs)
\end{itemize}

\subsection{\citet{liMultisiteFMRIAnalysis2020}}

\begin{itemize}
  \item 70\% with C-PAC preprocessing pipeline
  \item similar number of subjects to us
  \item used sliding windows (32 timepoints long) of mean ROI sequences (HO Atlas, 111 ROIs)
  \item interesting comparison points is \emph{sex classification accuracy} which was only between
  \item report no overall accuracy, but NYU hardest to classify (67.6\% at best), USM easiest (up to
  84.9\%)
  \item validation splits are unclear
\end{itemize}

\subsection{\citet{el-gazzarHybrid3DCNN3DCLSTM2019}}

\begin{itemize}
  \item used Conv3D to Conv1D or ConvLSTM (they test both)
  \item CPAC pipeline for ABIDE
  \item only use single-site validation (losers) also NYU and UM (easiest)
  \item also do one multi-site with 19 sites 1100 subjects
  \item patch-based training where prediction is average prediction over crops
  \item max 5-fold acc of \(0.77 \pm 0.05\) on NYU with Conv3dConvLSTM3d
\end{itemize}

\begin{table}
\caption{\citet{el-gazzarHybrid3DCNN3DCLSTM2019} 5-fold cross-site results}
\centering
  \begin{tabular}{lll}
    \toprule
    % \multicolumn{2}{c}{Part}                   \\
    % \cmidrule(r){1-2}
    Model     & Accuracy     & F1-score \\
    \midrule
    AE MLP        [8]   &  0.63 \(\pm\) 0.02  & 0.64 \\
    SVM           [5]   &  0.58 \(\pm\) 0.04  & 0.60 \\
    1D Conv       [7]   &  0.64 \(\pm\) 0.06  & 0.64 \\
    3DCNN 1D     (ours) &  0.54 \(\pm\) 0.02  & 0.50 \\
    3DCNN C-LSTM (ours) &  0.58 \(\pm\) 0.03  & 0.53 \\

    \bottomrule
  \end{tabular}
  \label{tab:table}
\end{table}

\subsection{\citet{shaoClassificationASDBased2021}}

\begin{itemize}
  \item GCN (graph convolutional network) plus another network that learns feature weights
  \item use CPAC preprocessed data, but \textbf{discard 241 ghosty / bad-looking data} to get a
  total of 871 subjects
  \item used mean series on some of HO (Harvard-Oxford) atlas, standardized to zero mean and unit variance
  \item 111 ROIs total
  \item do feature selection and also test various models
  \item GCN gets \(79.5\pm3.3\)\% acc (3.3 is sd), 10-fold validation
\end{itemize}

\subsection{\citet{dekhilUsingRestingState2018}}
\begin{itemize}
  \item  fMRI data for 123 ASD and 160 TD children and adolescents (for a total number of 283
  subjects) from the National Database for Autism Research (NDAR: http://ndar.nih.gov)
  \item all Ps have both MRI and rs-fMRI scans
  \item do register, BET, slicetime, motion, and then spatial Gaussian spatial smoothing
  \item extract 34 ROIs via ICA
  \item features for prediction are the \textbf{power spectral densities}
  \item get very high accuracy, but isn't ABIDE, and is one site
\end{itemize}

\subsection{\citet{parisotDiseasePredictionUsing2018}}
\begin{itemize}
  \item ``Our analysis shows that our novel framework can improve over state-of-the-art results on
  both databases, with 70.4\% classification accuracy for ABIDE''
  \item 871 subjects (remove a lot of bad scans) from CPAC pipeline
  \item GCN on correlation matrices between HO atlas mean ROI signals (plus some fancy normalization
  / filtering), with recursive feature selection
  \item stratified grouped 10-fold to get the 70.4\% acc
\end{itemize}

\subsection{\citet{sakaiMachineLearningStudies2019}}

See Table 9 of this one for ABIDE accuracies. There are some spuriously high and extremely unlikely
out-of-bag accuracies of 0.90 or on tiny sample. Otherwise, of note is
\citet{iidakaRestingStateFunctional2015} who apparently get an LOOCV of 0.90 (??? dubious).

\subsection{\citet{iidakaRestingStateFunctional2015}}

\begin{itemize}
  \item only subjects under 20
  \item 640 subjects total
  \item 2-fold acc was 77.2\%, 10-fold was 86.9\%
  \item did do some bandpass filtering as pre-processing, drop first 5 volumes
  \item features are 90 AAL mean normalized ROI regions correlation matrix (r-values fisher
  normalized to Z-scores)
\end{itemize}

\subsection{\citet{liNovelTransferLearning2018}}

\begin{itemize}
  \item pre-train stacked autoencoder on different data healthy rs-fMRI first
  \item ABIDE used Connectome Computation System preprocessed
  \item \textbf{regressed out height, age, sex, site} from among ROI correlations
  \item never get above 70.4\% acc, and only within USM, so not good
\end{itemize}

\subsection{\citet{kazeminejadTopologicalPropertiesRestingState2019}}

\begin{itemize}
  \item CPAC pipeline, 116 AAL regions
  \item features are multiple correlation matrices (e.g. Pearson, Spearman, partial correlation,
  mutual information) converted to graphs via thresholding
  \item Gaussian SVM classifier (sklearn), step-up feature selection
  \item validation is 10-fold, but very dubious procedure, sounds / unclear how feature selection is
  being done here, almost certainly overfitting a lot
  \item no overall reported accuracy, just report stratified by ages, sad, lame, (lol Frontiers)
\end{itemize}

\subsection{\citet{eslamiASDDiagNetHybridLearning2019}}

\begin{itemize}
  \item
\end{itemize}

\section{Headings: first level}
\label{sec:headings}

See Section \ref{sec:headings}.

\subsection{Headings: second level}
\paragraph{Paragraph}

A footnote \footnote{Sample of the first footnote.}.

\bibliographystyle{unsrtnat}
\bibliography{references}

\end{document}